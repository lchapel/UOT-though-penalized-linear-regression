{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import ot\n",
    "import time\n",
    "import scipy.stats as st\n",
    "\n",
    "from solvers import solvers_L2_UOT as sl2\n",
    "from solvers import solver_kl_UOT as skl\n",
    "from solvers import solver_semirelax_L2_UOT as ssrl2\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "Both of the source and the target samples are 10-dimensional vectors drawn from a Gaussian distribution ($n = m = 1000$), and the cost matrix $C$ is computed by l2-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "dim = 10\n",
    "nb_run = 5       # 5 runs \n",
    "sigma = np.eye(dim)*2\n",
    "m = np.arange(0,dim)\n",
    "sigma2 = np.eye(dim)\n",
    "m2 = np.arange(5,dim+5)\n",
    "\n",
    "a_list = []\n",
    "b_list = []\n",
    "C_list = []\n",
    "coef_list = []\n",
    "balanced_distance = []\n",
    "\n",
    "for i in range(nb_run):\n",
    "    np.random.seed(i)\n",
    "    xs = np.random.randn(n, dim).dot(sigma) + m\n",
    "    np.random.seed(i+100)\n",
    "    xt = np.random.randn(n, dim).dot(sigma2) + m2\n",
    "\n",
    "    np.random.seed(i)\n",
    "    a = np.random.normal(100,10,n)\n",
    "    a = a / np.sum(a)\n",
    "    a_list.append(a)\n",
    "    np.random.seed(i + 100)\n",
    "    b = np.random.normal(100, 10, n)\n",
    "    b = b / np.sum(b)\n",
    "    b_list.append(b)\n",
    "    C = ot.dist(xs, xt)\n",
    "    C = C / C.max()\n",
    "    C_list.append(C)\n",
    "\n",
    "    # solution of balanced OT \n",
    "    G0 = ot.emd(a, b, C)\n",
    "    balanced_distance.append(np.sum(G0 * C))\n",
    "\n",
    "    # compute the tolerance coefficient in solver Celer\n",
    "    y = np.concatenate((a, b))\n",
    "    coef = np.linalg.norm(y) ** 2 / len(y)\n",
    "    coef_list.append(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2-penalized UOT with different solvers and different $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "maxiter = 200000\n",
    "tol = 1e-7\n",
    "tol_dual = 1e-4\n",
    "reg_list = np.geomspace(10, 20000, num=15)\n",
    "\n",
    "ot_cost_lasso_all = []\n",
    "ot_cost_lasso_cd_all = []\n",
    "ot_cost_bfgs_all = []\n",
    "ot_cost_regpath_all = []\n",
    "ot_cost_mu_all = []\n",
    "\n",
    "timing_lasso_all = []\n",
    "timing_lasso_cd_all = []\n",
    "timing_bfgs_all = []\n",
    "timing_regpath_all = []\n",
    "timing_mu_all = []\n",
    "\n",
    "sol_lasso_all = []\n",
    "sol_lasso_cd_all = []\n",
    "sol_bfgs_all = []\n",
    "sol_regpath_all = []\n",
    "sol_mu_all = []\n",
    "\n",
    "for i in range(nb_run):\n",
    "    ot_cost_lasso = []\n",
    "    ot_cost_lasso_cd = []\n",
    "    ot_cost_bfgs = []\n",
    "    ot_cost_regpath = []\n",
    "    ot_cost_mu = []\n",
    "\n",
    "    timing_lasso = []\n",
    "    timing_lasso_cd = []\n",
    "    timing_bfgs = []\n",
    "    timing_regpath = []\n",
    "    timing_mu = []\n",
    "    \n",
    "    sol_lasso = []\n",
    "    sol_lasso_cd = []\n",
    "    sol_bfgs = []\n",
    "    sol_regpath = []\n",
    "    sol_mu = []\n",
    "\n",
    "    a = a_list[i]\n",
    "    b = b_list[i]\n",
    "    C = C_list[i]\n",
    "    for reg in reg_list:\n",
    "        start = time.time()\n",
    "        Gl = sl2.ot_ul2_solve_lasso_celer(C, a, b, reg,  maxiter, tol_dual*coef_list[i])\n",
    "        timing_lasso.append(time.time()-start)\n",
    "        sol_lasso.append(Gl)\n",
    "        ot_cost_lasso.append(np.sum(Gl*C))\n",
    "\n",
    "        start = time.time()\n",
    "        Gl2 = sl2.ot_ul2_solve_lasso_cd(C, a, b, reg, maxiter, tol_dual)\n",
    "        timing_lasso_cd.append(time.time()-start)\n",
    "        sol_lasso_cd.append(Gl2)\n",
    "        ot_cost_lasso_cd.append(np.sum(Gl2*C))\n",
    "\n",
    "        # BFGS tol = 1e-12\n",
    "        start = time.time()\n",
    "        Gss = sl2.ot_ul2_solve_BFGS(C,a,b,reg, maxiter, 1e-12)\n",
    "        timing_bfgs.append(time.time()-start)\n",
    "        sol_bfgs.append(Gss)\n",
    "        ot_cost_bfgs.append(np.sum(Gss*C))\n",
    "\n",
    "        start = time.time()\n",
    "        Grp, _, _, _ = sl2.ot_ul2_reg_path(a, b, C, reg, savePi=False)\n",
    "        timing_regpath.append(time.time()-start)\n",
    "        sol_regpath.append(Grp)\n",
    "        ot_cost_regpath.append(np.sum(Grp*C))\n",
    "\n",
    "        start = time.time()\n",
    "        Gmu = sl2.ot_ul2_solve_mu(C, a, b, reg, maxiter, tol)\n",
    "        timing_mu.append(time.time()-start)\n",
    "        sol_mu.append(Gmu)\n",
    "        ot_cost_mu.append(np.sum(Gmu*C))\n",
    "        \n",
    "    ot_cost_lasso_all.append(ot_cost_lasso)\n",
    "    ot_cost_lasso_cd_all.append(ot_cost_lasso_cd)\n",
    "    ot_cost_bfgs_all.append(ot_cost_bfgs)\n",
    "    ot_cost_regpath_all.append(ot_cost_regpath)\n",
    "    ot_cost_mu_all.append(ot_cost_mu)\n",
    "\n",
    "    timing_lasso_all.append(timing_lasso)\n",
    "    timing_lasso_cd_all.append(timing_lasso_cd)\n",
    "    timing_bfgs_all.append(timing_bfgs)\n",
    "    timing_regpath_all.append(timing_regpath)\n",
    "    timing_mu_all.append(timing_mu)\n",
    "    \n",
    "    sol_lasso_all.append(sol_lasso)\n",
    "    sol_lasso_cd_all.append(sol_lasso_cd)\n",
    "    sol_bfgs_all.append(sol_bfgs)\n",
    "    sol_regpath_all.append(sol_regpath)\n",
    "    sol_mu_all.append(sol_mu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL-penalized UOT with different solvers and different $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ot_cost_bfgs_kl_all = []\n",
    "ot_cost_mu_kl_all = []\n",
    "timing_bfgs_kl_all = []\n",
    "timing_mu_kl_all = []\n",
    "sol_bfgs_kl_all = []\n",
    "sol_mu_kl_all = []\n",
    "\n",
    "maxiter = 200000\n",
    "tol = 1e-7\n",
    "\n",
    "reg_list = np.geomspace(0.01, 150, num=15)\n",
    "for i in range(nb_run):\n",
    "    ot_cost_bfgs_kl = []\n",
    "    ot_cost_mu_kl = []\n",
    "    timing_bfgs_kl = []\n",
    "    timing_mu_kl = []\n",
    "    sol_bfgs_kl = []\n",
    "    sol_mu_kl = []\n",
    "    \n",
    "    a = a_list[i]\n",
    "    b = b_list[i]\n",
    "    C = C_list[i]\n",
    "    for reg in reg_list:\n",
    "        start = time.time()\n",
    "        G1 = skl.ot_ukl_solve_BFGS(C, a, b, reg, maxiter, tol)\n",
    "        timing_bfgs_kl.append(time.time()-start)\n",
    "        sol_bfgs_kl.append(G1)\n",
    "        ot_cost_bfgs_kl.append(np.sum(G1*C))\n",
    "\n",
    "        start = time.time()\n",
    "        Gmu = skl.ot_ukl_solve_mu(C, a, b, reg, maxiter, tol)\n",
    "        timing_mu_kl.append(time.time()-start)\n",
    "        sol_mu_kl.append(Gmu)\n",
    "        ot_cost_mu_kl.append(np.sum(Gmu*C))\n",
    "    \n",
    "    ot_cost_bfgs_kl_all.append(ot_cost_bfgs_kl)\n",
    "    ot_cost_mu_kl_all.append(ot_cost_mu_kl)\n",
    "    timing_bfgs_kl_all.append(timing_bfgs_kl)\n",
    "    timing_mu_kl_all.append(timing_mu_kl)\n",
    "    sol_bfgs_kl_all.append(sol_bfgs_kl)\n",
    "    sol_mu_kl_all.append(sol_mu_kl)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization path with different size of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "niter_list_all = []\n",
    "timings_list_all = []\n",
    "\n",
    "# generate 10-dimsensional source and target samples \n",
    "dim = 10\n",
    "sigma = np.eye(dim)*2\n",
    "m = np.arange(0,dim)\n",
    "sigma2 = np.eye(dim)\n",
    "m2 = np.arange(5,dim+5)\n",
    "n_list = np.linspace(100, 1000, 10, endpoint=True, dtype=int)\n",
    "nb_run = 5\n",
    "# compute the regularization path for different size of source and target samples\n",
    "for i in range(nb_run):\n",
    "    niter_list = []\n",
    "    timings_list = []\n",
    "    for n in n_list:    \n",
    "        np.random.seed(n+i)\n",
    "        xs = np.random.randn(n, dim).dot(sigma) + m\n",
    "        np.random.seed(2*n+i)\n",
    "        xt = np.random.randn(n, dim).dot(sigma2) + m2\n",
    "        np.random.seed(n+i)\n",
    "        a = np.random.normal(100,10,n)\n",
    "        a /= np.sum(a)\n",
    "        np.random.seed(2*n+i)\n",
    "        b = np.random.normal(100,10,n)\n",
    "        b /= np.sum(b)\n",
    "        C = ot.dist(xs, xt)\n",
    "        C = C/C.max()\n",
    "\n",
    "        start = time.time()\n",
    "        _, _, _, niter = sl2.ot_ul2_reg_path(a, b, C, savePi=False)\n",
    "        t =  time.time()-start\n",
    "        niter_list.append(niter)\n",
    "        timings_list.append(t)\n",
    "        \n",
    "    niter_list_all.append(niter_list)\n",
    "    timings_list_all.append(timings_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bfgs = np.array(timing_bfgs_all)\n",
    "data_mu = np.array(timing_mu_all)\n",
    "data_regpath = np.array(timing_regpath_all)\n",
    "data_celer = np.array(timing_lasso_all)\n",
    "data_cd = np.array(timing_lasso_cd_all)\n",
    "\n",
    "# calculate confidence interval of l2 penalized UOT\n",
    "low_CI_bound_bfgs, high_CI_bound_bfgs = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_bfgs, 0), scale=st.sem(data_bfgs))\n",
    "low_CI_bound_mu, high_CI_bound_mu = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_mu, 0), scale=st.sem(data_mu))\n",
    "low_CI_bound_regpath, high_CI_bound_regpath = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_regpath, 0), scale=st.sem(data_regpath))\n",
    "low_CI_bound_celer, high_CI_bound_celer = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_celer, 0), scale=st.sem(data_celer))\n",
    "low_CI_bound_cd, high_CI_bound_cd = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_cd, 0), scale=st.sem(data_cd))\n",
    "\n",
    "data_bfgs_kl = np.array(timing_bfgs_kl_all)\n",
    "data_mu_kl = np.array(timing_mu_kl_all)\n",
    "# calculate confidence interval of kl penalized UOT\n",
    "low_CI_bound_bfgs_kl, high_CI_bound_bfgs_kl = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_bfgs_kl, 0), scale=st.sem(data_bfgs_kl))\n",
    "low_CI_bound_mu_kl, high_CI_bound_mu_kl = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_mu_kl, 0), scale=st.sem(data_mu_kl))\n",
    "\n",
    "data_time_regpath = np.array(timings_list_all)\n",
    "# calculate confidence interval of timings of regularization path\n",
    "low_CI_bound, high_CI_bound = st.t.interval(0.95, nb_run - 1, loc=np.mean(data_time_regpath, 0), scale=st.sem(data_time_regpath))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4), constrained_layout=True)\n",
    "gs = GridSpec(1, 3, figure=fig, width_ratios=[1,1,1])\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"],\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\":42, \n",
    "    \"font.size\": 16})\n",
    "\n",
    "# Left panel \n",
    "ax1.loglog(n_list, np.mean(data_time_regpath, 0), linestyle = '-', marker = '^', markersize=4)\n",
    "ax1.fill_between(n_list, low_CI_bound, high_CI_bound, alpha=0.25)\n",
    "\n",
    "ax1.set_xlabel(\"number of points (n=m)\", fontsize=14)\n",
    "ax1.set_ylabel(\"Time(sec)\", fontsize=14)\n",
    "ax1.grid(which='both')\n",
    "ax1.set_title(\"Regularization path\", fontsize=18)\n",
    "\n",
    "\n",
    "# center panel\n",
    "reg_list = np.geomspace(10, 20000, num=15)\n",
    "ax2.loglog(reg_list, np.mean(data_bfgs, 0), label = 'BFGS', linestyle = '-.', marker = '^', markersize=4, c='green')\n",
    "ax2.loglog(reg_list, np.mean(data_mu, 0), label = 'Multiplicative update', linestyle = '--', marker = 'v', markersize=4, c='orange')\n",
    "ax2.loglog(reg_list, np.mean(data_celer, 0), label = 'Lasso (celer)', linestyle = ':', marker = 'd', markersize=4, c='brown')\n",
    "ax2.loglog(reg_list, np.mean(data_cd, 0), label = 'Lasso (CD)', linestyle = '--', marker = 'D', markersize=4, c='c')\n",
    "ax2.loglog(reg_list, np.mean(data_regpath, 0), label = 'Regularization path', linestyle = '-', marker = 's', markersize=4, c='m')\n",
    "\n",
    "# plot confidence interval\n",
    "ax2.fill_between(reg_list, low_CI_bound_bfgs, high_CI_bound_bfgs, alpha=0.25, color = 'green')\n",
    "ax2.fill_between(reg_list, low_CI_bound_mu, high_CI_bound_mu, alpha=0.25, color = 'orange')\n",
    "ax2.fill_between(reg_list, low_CI_bound_celer, high_CI_bound_celer, alpha=0.25, color = 'brown')\n",
    "ax2.fill_between(reg_list, low_CI_bound_cd, high_CI_bound_cd, alpha=0.25, color = 'c')\n",
    "ax2.fill_between(reg_list, low_CI_bound_regpath, high_CI_bound_regpath, alpha=0.25, color = 'm')\n",
    "\n",
    "ax2.set_xlabel(\"$\\lambda$\", fontsize=14)\n",
    "ax2.set_ylabel(\"Time (sec)\", fontsize=14)\n",
    "ax2.set_title('$\\ell_2$-penalized UOT', fontsize=18)\n",
    "ax2.legend(fontsize=12, loc = 'lower right')\n",
    "ax2.grid()\n",
    "\n",
    "# Right panel\n",
    "reg_list = np.geomspace(0.01, 150, num=15)\n",
    "ax3.loglog(reg_list, np.mean(data_bfgs_kl, 0), label = 'BFGS', linestyle = '--', marker = '^', markersize=4, c='green')\n",
    "ax3.loglog(reg_list, np.mean(data_mu_kl, 0), label = 'Multiplicative update', linestyle = '-.', marker = 'v', markersize=4, c='orange')\n",
    "\n",
    "# plot confidence interval\n",
    "ax3.fill_between(reg_list, low_CI_bound_bfgs_kl, high_CI_bound_bfgs_kl, alpha=0.25, color = 'green')\n",
    "ax3.fill_between(reg_list, low_CI_bound_mu_kl, high_CI_bound_mu_kl, alpha=0.25, color = 'orange')\n",
    "\n",
    "ax3.set_xlabel(\"$\\lambda$\",fontsize=14)\n",
    "ax3.set_ylabel(\"Time (sec)\", fontsize=14)\n",
    "ax3.set_title('KL-penalized UOT', fontsize=18)\n",
    "ax3.legend(fontsize=12, loc = 'lower right')\n",
    "ax3.grid()\n",
    "\n",
    "# plt.savefig('simu.pdf', bbox_inches='tight', pad_inches=0) \n",
    "plt.savefig('simu.jpg', bbox_inches='tight', pad_inches=0) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### empirical complexity of regularization path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.polyfit(np.log(n_list), np.log(np.mean(data_time_regpath, 0)), 1)\n",
    "z2 = np.polyfit(np.log(n_list)[3:], np.log(np.mean(data_time_regpath, 0)[3:]), 1)\n",
    "print('empirical complexity with all points:', z1[0]) \n",
    "print('empirical complexity with last 7 points:', z2[0]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
